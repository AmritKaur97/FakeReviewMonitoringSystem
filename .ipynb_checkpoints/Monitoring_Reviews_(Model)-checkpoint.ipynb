{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dfp_Avcr1Eu2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import pickle\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "zp52as7s44g3",
    "outputId": "55089bcc-068d-409f-b38d-39f0a88bfeb6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simra\\AppData\\Local\\Temp\\ipykernel_20292\\1478739245.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"reviews.csv\",sep=\"\\t\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>IP Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>20422322</td>\n",
       "      <td>R8MEA6IGAHO0B</td>\n",
       "      <td>B00MC4CED8</td>\n",
       "      <td>82850235</td>\n",
       "      <td>BlackVue DR600GW-PMP</td>\n",
       "      <td>Mobile_Electronics</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Very Happy!</td>\n",
       "      <td>As advertised. Everything works perfectly, I'm...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1.440988e+09</td>\n",
       "      <td>193.93.167.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>40835037</td>\n",
       "      <td>R31LOQ8JGLPRLK</td>\n",
       "      <td>B00OQMFG1Q</td>\n",
       "      <td>82850235</td>\n",
       "      <td>GENSSI GSM / GPS Two Way Smart Phone Car Alarm...</td>\n",
       "      <td>Mobile_Electronics</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>five star</td>\n",
       "      <td>it's great</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1.441002e+09</td>\n",
       "      <td>193.93.167.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>51469641</td>\n",
       "      <td>R2Y0MM9YE6OP3P</td>\n",
       "      <td>B00QERR5CY</td>\n",
       "      <td>82850235</td>\n",
       "      <td>iXCC Multi pack Lightning cable</td>\n",
       "      <td>Mobile_Electronics</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>great cables</td>\n",
       "      <td>These work great and fit my life proof case fo...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1.440959e+09</td>\n",
       "      <td>193.93.167.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>4332923</td>\n",
       "      <td>RRB9C05HDOD4O</td>\n",
       "      <td>B00QUFTPV4</td>\n",
       "      <td>82850235</td>\n",
       "      <td>abcGoodefg® FBI Covert Acoustic Tube Earpiece ...</td>\n",
       "      <td>Mobile_Electronics</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Work very well</td>\n",
       "      <td>Work very well</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1.441015e+09</td>\n",
       "      <td>193.93.167.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>44855305</td>\n",
       "      <td>R26I2RI1GFV8QG</td>\n",
       "      <td>B0067XVNTG</td>\n",
       "      <td>563475445</td>\n",
       "      <td>Generic Car Dashboard Video Camera Vehicle Vid...</td>\n",
       "      <td>Mobile_Electronics</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Cameras has battery issues</td>\n",
       "      <td>Be careful with these products, I have bought ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1.440973e+09</td>\n",
       "      <td>205.10.168.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     20422322   R8MEA6IGAHO0B  B00MC4CED8        82850235   \n",
       "1          US     40835037  R31LOQ8JGLPRLK  B00OQMFG1Q        82850235   \n",
       "2          US     51469641  R2Y0MM9YE6OP3P  B00QERR5CY        82850235   \n",
       "3          US      4332923   RRB9C05HDOD4O  B00QUFTPV4        82850235   \n",
       "4          US     44855305  R26I2RI1GFV8QG  B0067XVNTG       563475445   \n",
       "\n",
       "                                       product_title    product_category  \\\n",
       "0                               BlackVue DR600GW-PMP  Mobile_Electronics   \n",
       "1  GENSSI GSM / GPS Two Way Smart Phone Car Alarm...  Mobile_Electronics   \n",
       "2                    iXCC Multi pack Lightning cable  Mobile_Electronics   \n",
       "3  abcGoodefg® FBI Covert Acoustic Tube Earpiece ...  Mobile_Electronics   \n",
       "4  Generic Car Dashboard Video Camera Vehicle Vid...  Mobile_Electronics   \n",
       "\n",
       "  star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0           5            0.0          0.0    N                 Y   \n",
       "1           5            0.0          1.0    N                 Y   \n",
       "2           5            0.0          0.0    N                 Y   \n",
       "3           4            0.0          0.0    N                 Y   \n",
       "4           2            0.0          0.0    N                 Y   \n",
       "\n",
       "              review_headline  \\\n",
       "0                 Very Happy!   \n",
       "1                   five star   \n",
       "2                great cables   \n",
       "3              Work very well   \n",
       "4  Cameras has battery issues   \n",
       "\n",
       "                                         review_body review_date  \\\n",
       "0  As advertised. Everything works perfectly, I'm...  2015-08-31   \n",
       "1                                         it's great  2015-08-31   \n",
       "2  These work great and fit my life proof case fo...  2015-08-31   \n",
       "3                                    Work very well   2015-08-31   \n",
       "4  Be careful with these products, I have bought ...  2015-08-31   \n",
       "\n",
       "      timestamp     IP Address  \n",
       "0  1.440988e+09  193.93.167.87  \n",
       "1  1.441002e+09  193.93.167.87  \n",
       "2  1.440959e+09  193.93.167.87  \n",
       "3  1.441015e+09  193.93.167.87  \n",
       "4  1.440973e+09  205.10.168.66  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"reviews.csv\",sep=\"\\t\")\n",
    "# df.drop(columns= \"Unnamed: 0\",inplace = True)\n",
    "# df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5p0TgKzbGnh",
    "outputId": "fc84d345-d359-4418-dfba-fe92834b5d3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['marketplace', 'customer_id', 'review_id', 'product_id',\n",
       "       'product_parent', 'product_title', 'product_category', 'star_rating',\n",
       "       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
       "       'review_headline', 'review_body', 'review_date', 'timestamp',\n",
       "       'IP Address'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84qZW_xdbwwW",
    "outputId": "5572fee7-01e7-4855-ee22-16b235ace9aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace           0\n",
       "customer_id           0\n",
       "review_id             0\n",
       "product_id            0\n",
       "product_parent        0\n",
       "product_title         0\n",
       "product_category      0\n",
       "star_rating           5\n",
       "helpful_votes        13\n",
       "total_votes          13\n",
       "vine                 13\n",
       "verified_purchase    13\n",
       "review_headline      15\n",
       "review_body          14\n",
       "review_date          18\n",
       "timestamp            26\n",
       "IP Address            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jqiiloKr5WT8"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KnkvszYN8nhV",
    "outputId": "f86811fe-e6b0-481c-d30f-35c598e15dd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\simra\\anaconda3\\lib\\site-packages (1.0.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\simra\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\simra\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\simra\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\simra\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FiPfppR38th1"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmvwiUr6CVAo"
   },
   "source": [
    "#Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djqfQdqDXbXl",
    "outputId": "67bc2994-1cb3-4bca-86e5-5740e0bf2031"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Replace np.nan values with empty strings or other suitable value\n",
    "df[\"review_headline\"].fillna(\"\", inplace=True)\n",
    "df[\"review_body\"].fillna(\"\", inplace=True)\n",
    "\n",
    "# Convert 'star_rating' column to numeric, replace non-numeric values with NaN\n",
    "df[\"star_rating\"] = pd.to_numeric(df[\"star_rating\"], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in the 'star_rating' column\n",
    "df = df.dropna(subset=[\"star_rating\"])\n",
    "\n",
    "clf = LogisticRegression()\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Concatenate the review_headline and review_body into a single text column\n",
    "texts = df[\"review_headline\"] + \" \" + df[\"review_body\"]\n",
    "\n",
    "# Fit the TF-IDF vectorizer on your data\n",
    "tfidf.fit(texts)\n",
    "\n",
    "# Transform the text data using the fitted TF-IDF vectorizer\n",
    "transformed_texts = tfidf.transform(texts)\n",
    "\n",
    "# Fit the classifier on the transformed texts and corresponding sentiments\n",
    "clf.fit(transformed_texts, df[\"star_rating\"])\n",
    "\n",
    "with open(\"classifier.pickle\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "with open(\"TfidfModel.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "# Load the classifier and TF-IDF vectorizer from the pickle files\n",
    "with open(\"classifier.pickle\", \"rb\") as f:\n",
    "    clf = pickle.load(f)\n",
    "\n",
    "with open(\"TfidfModel.pickle\", \"rb\") as f:\n",
    "    tfidf = pickle.load(f)\n",
    "\n",
    "def getSentiment(text):\n",
    "    # PREPROCESSING THE DATASET\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"that's\",\"that is\",text)\n",
    "    text = re.sub(r\"there's\",\"there is\",text)\n",
    "    text = re.sub(r\"what's\",\"what is\",text)\n",
    "    text = re.sub(r\"where's\",\"where is\",text)\n",
    "    text = re.sub(r\"it's\",\"it is\",text)\n",
    "    text = re.sub(r\"who's\",\"who is\",text)\n",
    "    text = re.sub(r\"i'm\",\"i am\",text)\n",
    "    text = re.sub(r\"she's\",\"she is\",text)\n",
    "    text = re.sub(r\"he's\",\"he is\",text)\n",
    "    text = re.sub(r\"they're\",\"they are\",text)\n",
    "    text = re.sub(r\"who're\",\"who are\",text)\n",
    "    text = re.sub(r\"ain't\",\"am not\",text)\n",
    "    text = re.sub(r\"wouldn't\",\"would not\",text)\n",
    "    text = re.sub(r\"shouldn't\",\"should not\",text)\n",
    "    text = re.sub(r\"can't\",\"can not\",text)\n",
    "    text = re.sub(r\"couldn't\",\"could not\",text)\n",
    "    text = re.sub(r\"won't\",\"will not\",text)\n",
    "\n",
    "    text = re.sub(r\"\\W\",\" \",text)\n",
    "    text = re.sub(r\"\\d\",\" \",text)\n",
    "    text = re.sub(r\"\\s+[a-z]\\s+\",\" \",text)\n",
    "    text = re.sub(r\"^[a-z]\\s+\",\" \",text)\n",
    "    text = re.sub(r\"\\s+[a-z]$\",\" \",text)\n",
    "    text = re.sub(r\"\\s+\",\" \",text)\n",
    "\n",
    "    sent = clf.predict(tfidf.transform([text]).toarray())\n",
    "\n",
    "    return sent[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSentiment('Super good product this is bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Very Happy!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review_headline[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As advertised. Everything works perfectly, I'm very happy with the camera. As a matter of fact I'm going to buy another one for my 2nd car.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.review_body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not fake\n"
     ]
    }
   ],
   "source": [
    "if getSentiment(df.review_headline[0]) != getSentiment(df.review_body[0]):\n",
    "    print('fake')\n",
    "else:\n",
    "    print('not fake')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1Zz_Ycgh_dQ"
   },
   "source": [
    "#1.Monitoring reviews which have different review headline and review body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7sDw4OyiCcv0"
   },
   "outputs": [],
   "source": [
    "# 1. Different sentiment in review headline and review body\n",
    "remove_reviews = []\n",
    "# Stores the list of review_id of fake reviews\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # Iterate through the whole dataset\n",
    "    if getSentiment(df[\"review_headline\"].iloc[i]) != getSentiment(df[\"review_body\"].iloc[i]):\n",
    "\n",
    "        # Checking if the sentiment of the body and the headline are not the same\n",
    "        remove_reviews.append(df[\"review_id\"].iloc[i])\n",
    "            # append review_id to the list of fake reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vk8nAzzj5agQ",
    "outputId": "f4eff364-ab12-478f-d90e-93162c74abd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29319"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqJdCEu1iNkD"
   },
   "source": [
    "#2. Reviews in which same user promoting or demoting a particular brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "customers = df.groupby(\"customer_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10071,\n",
       "        marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "  24504          US        10071  R1XALU24Y932WC  B0048DLA90       864204912   \n",
       "  \n",
       "                                             product_title    product_category  \\\n",
       "  24504  NEW Click Wheel Flex Cable For Apple iPod Nano...  Mobile_Electronics   \n",
       "  \n",
       "         star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "  24504          5.0            0.0          0.0    N                 Y   \n",
       "  \n",
       "        review_headline                  review_body review_date     timestamp  \\\n",
       "  24504      Five Stars  Just what I needed. Thanks.  2014-07-31  1.406830e+09   \n",
       "  \n",
       "              IP Address  \n",
       "  24504  217.156.205.162  ),\n",
       " (10190,\n",
       "        marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "  36603          US        10190  R2RIK102DIC8UF  B000IEB034       292242642   \n",
       "  \n",
       "                                             product_title    product_category  \\\n",
       "  36603  Huawei Ascend W1 Case, BoxWave [BodySuit] Prem...  Mobile_Electronics   \n",
       "  \n",
       "         star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "  36603          4.0            0.0          0.0    N                 Y   \n",
       "  \n",
       "        review_headline                                        review_body  \\\n",
       "  36603   seems to work  I like it. It isn't big and bulky like some ot...   \n",
       "  \n",
       "        review_date     timestamp    IP Address  \n",
       "  36603  2013-12-07  1.386408e+09  202.26.116.3  ),\n",
       " (12443,\n",
       "        marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "  54220          US        12443  R1ILKG291YE4A3  B006Y442AU       419796474   \n",
       "  \n",
       "                                             product_title    product_category  \\\n",
       "  54220  Pioneer AVH-P8400BH 2-DIN Multimedia DVD Recei...  Mobile_Electronics   \n",
       "  \n",
       "         star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "  54220          5.0            0.0          2.0    N                 Y   \n",
       "  \n",
       "                review_headline  \\\n",
       "  54220  VÍCTOR MANUEL GALLARDO   \n",
       "  \n",
       "                                               review_body review_date  \\\n",
       "  54220  MUY RECOMENDABLE CUMPLE CON LAS EXPECTATIVAS, ...  2012-12-18   \n",
       "  \n",
       "            timestamp    IP Address  \n",
       "  54220  1.355779e+09  202.28.133.6  )]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(customers)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users which are posting either all positive or negative reviews on different products of same brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzQ8f-1oo3tz"
   },
   "outputs": [],
   "source": [
    "#2. Users which are posting either all positive or negative reviews on different products of same brand\n",
    "\n",
    "customers = df.groupby(\"customer_id\")\n",
    "# groups dataset by customers\n",
    "\n",
    "customer_list = df[\"customer_id\"].unique()\n",
    "# list of unique customers\n",
    "\n",
    "size = len(customer_list.tolist())\n",
    "# size of total unique customers\n",
    "\n",
    "for i in range(size):\n",
    "    # iterate through all the customers\n",
    "\n",
    "    brand_df = customers.get_group(customer_list[i])\n",
    "    # Dataframe for each customers\n",
    "\n",
    "    brands = brand_df.groupby(\"product_parent\")\n",
    "    # groups reviews of each customers by brand\n",
    "\n",
    "    brands_list = brand_df[\"product_parent\"].unique()\n",
    "    # unique list of brands for each customers reviews\n",
    "\n",
    "    no_of_brands = len(brands_list.tolist())\n",
    "    # no. of brands for which reviews had been written by the customer\n",
    "\n",
    "    for j in range(no_of_brands):\n",
    "        # iterate through all the brands\n",
    "\n",
    "        product_df = brands.get_group(brands_list[j])\n",
    "        # Dataframe of products for a brand for which a customer had written reviews\n",
    "\n",
    "        no_of_products = len(product_df[\"product_id\"])\n",
    "        # no of products\n",
    "\n",
    "        if no_of_products<=2:\n",
    "            # it will filter the products which are less than 2 for a brand\n",
    "            continue\n",
    "\n",
    "        indices = product_df.index.values.tolist()\n",
    "        # index of the dataframe of the products of each brand for each customers\n",
    "\n",
    "        sentiment = getSentiment(product_df[\"review_body\"][indices[0]])\n",
    "        # sentiment of the review of the first product\n",
    "\n",
    "        isSameSentiment = True\n",
    "\n",
    "        #discarding those cases in which we have only less than 3 reviews on same brand\n",
    "        if(no_of_products<4):\n",
    "            continue\n",
    "\n",
    "        for k in range(1,no_of_products):\n",
    "            # iterate through all the products\n",
    "\n",
    "            text = str(product_df[\"review_body\"][indices[k]])\n",
    "            # review of each product\n",
    "\n",
    "            if getSentiment(text)!=sentiment :\n",
    "                # if sentiment is different than discard it\n",
    "                isSameSentiment = False\n",
    "                break;\n",
    "\n",
    "        if(isSameSentiment):\n",
    "            # if sentiments of all the products of same brand by a customer is same,\n",
    "            #append customer_id to blocked users list\n",
    "\n",
    "            remove_reviews.append(customer_list[i])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJGp8dMFpDQU",
    "outputId": "c3314b19-1e8a-4a00-9134-8be075d697e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29516"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nm9GUH-HiioZ"
   },
   "source": [
    "#3. Reviews in which person from same IP Address promoting or demoting a particular brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "st-8gi0E0EBP"
   },
   "outputs": [],
   "source": [
    "#3.Reviews from same IP either all positive or negative reviews on different products of same brand\n",
    "\n",
    "\n",
    "ip = df.groupby(\"IP Address\")\n",
    "#grouping the dataset by ip address\n",
    "\n",
    "ip_list = df[\"IP Address\"].unique()\n",
    "#stores the list pf unique ip addresses\n",
    "\n",
    "remove_ip = []\n",
    "#stores the list of ip address from where reviews have been written.\n",
    "\n",
    "size = len(ip_list.tolist())\n",
    "#stores the size of the total unique ip addresses\n",
    "\n",
    "for i in range(size):\n",
    "    # iterate through all the ip addresses\n",
    "\n",
    "    brand_df = ip.get_group(ip_list[i])\n",
    "    # Dataframe of brands for which reviews have been written from the same ip address\n",
    "\n",
    "    brands = brand_df.groupby(\"product_parent\")\n",
    "    # grouping the products of the same brands for each ip addresses\n",
    "\n",
    "    brands_list = brand_df[\"product_parent\"].unique()\n",
    "    #list of unique brands for each ip addresses\n",
    "\n",
    "    no_of_brands = len(brands_list.tolist())\n",
    "    # total no. of brands\n",
    "\n",
    "    for j in range(no_of_brands):\n",
    "        # iterate through all the brands\n",
    "\n",
    "        product_df = brands.get_group(brands_list[j])\n",
    "        # Dataframe of the products of each brand of each products\n",
    "\n",
    "        no_of_products = len(product_df[\"product_id\"])\n",
    "        # no of products of each brand for each ip addresses\n",
    "\n",
    "        if no_of_products<=2:\n",
    "            # filter the reviews of the brandswith less than 3 reviews\n",
    "            break\n",
    "\n",
    "        indices = product_df.index.tolist()\n",
    "        # indices of dataframe of products of each brand for each customers\n",
    "\n",
    "        sentiment = getSentiment(product_df[\"review_body\"][ indices[0] ])\n",
    "        # sentiment of review of first product of each brand\n",
    "\n",
    "        isSameSentiment = True\n",
    "\n",
    "        for k in range(1,no_of_products):\n",
    "            # iterate through all the reviews\n",
    "\n",
    "            text = str(product_df[\"review_body\"][indices[k]])\n",
    "            # reviews of each product\n",
    "\n",
    "            if getSentiment(text)!=sentiment :\n",
    "                # if sentiment of 2 products of same brand are not same\n",
    "                # then check the next brand\n",
    "                isSameSentiment = False\n",
    "                break;\n",
    "\n",
    "        if(isSameSentiment):\n",
    "            # if all the sentiments are same , append ip to blocked list\n",
    "            remove_ip.append(ip_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sWYRi5tHMrz",
    "outputId": "e46ec78b-b4a6-4491-a2d1-825b60310371"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['193.93.167.87']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YZyYkgMjchB"
   },
   "source": [
    "#4. Reviews which are posted as flood by same user all the reviews are either positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WgzVTBFZIvNj"
   },
   "outputs": [],
   "source": [
    "df.sort_values(\"customer_id\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebbNZpA6I2Ci"
   },
   "outputs": [],
   "source": [
    "#4. User posting (>3) reviews on the same day with all the reviews are either positive or negative.\n",
    "\n",
    "customer_group = df.groupby(\"customer_id\")\n",
    "#creates the group of the customers\n",
    "\n",
    "customer_group_list = df[\"customer_id\"].unique().tolist()\n",
    "# list of unique customers\n",
    "\n",
    "for i in range(len(customer_group_list)):\n",
    "    # iterate through all customers , starts with 1 as column could not be included\n",
    "\n",
    "    customer_reviews = customer_group.get_group( customer_group_list[i] )\n",
    "    # Dataframe of data of each cutomers\n",
    "\n",
    "    dates_list = customer_reviews[\"review_date\"].unique().tolist()\n",
    "    # list of dates of reviews written by each customers\n",
    "\n",
    "    reviews_by_date = customer_reviews.groupby(\"review_date\");\n",
    "    # gouping reviews by date for each cutomers\n",
    "\n",
    "    for j in range(len(dates_list)):\n",
    "        # iterating through all dates\n",
    "\n",
    "        reviews_by_date_for_pos = []\n",
    "        reviews_by_date_for_neg = []\n",
    "\n",
    "        df = reviews_by_date.get_group(dates_list[j])\n",
    "        #dataframe storing the details for each details for each customers\n",
    "\n",
    "        indices = df.index.tolist()\n",
    "        # indices of dataframe of each date\n",
    "\n",
    "        for k in range(len(df)):\n",
    "            # iterating through dataframe of each day for each customers\n",
    "\n",
    "            text = df[\"review_body\"][ indices[k] ]\n",
    "            #review on a single day\n",
    "\n",
    "            if(getSentiment(text) == 0):\n",
    "\n",
    "                #if sentiment is negative, append review_id to list of negative reviews\n",
    "                reviews_by_date_for_neg.append(df[\"review_id\"][ indices[k] ])\n",
    "\n",
    "            else:\n",
    "\n",
    "                #if sentiment is positive, append review_id to list of positive reviews\n",
    "                reviews_by_date_for_pos.append(df[\"review_id\"][ indices[k] ])\n",
    "\n",
    "        # CONDITION FOR CONSIDERING THE FAKE REVIEW\n",
    "\n",
    "        #removing postive reviews that are written by a reviewer that are > 3 on same day\n",
    "        if(len(reviews_by_date_for_pos)>3):\n",
    "            remove_reviews.extend(reviews_by_date_for_pos)\n",
    "\n",
    "        #removing postive reviews that are written by a reviewer that are > 3 on same day\n",
    "        if(len(reviews_by_date_for_neg)>3):\n",
    "            remove_reviews.extend(reviews_by_date_for_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zx6uxsIALT8E",
    "outputId": "f3e693d9-b4e7-4ea0-c97d-cf48fffdf906"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29516"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove_reviews)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNiLVO9MlS5i"
   },
   "source": [
    "#5. Reviews which are posted as flood by same person from same IP Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cy7syYU3LVWJ"
   },
   "outputs": [],
   "source": [
    "#5. Reviews(>3) from same IP on the same day with all the reviews are either positive or negative.\n",
    "\n",
    "ip_group = df.groupby(\"IP Address\")\n",
    "# grouping the dataset by ip addresses\n",
    "\n",
    "ip_list = df[\"IP Address\"].unique().tolist()\n",
    "# stores the list of unique ip addresses\n",
    "\n",
    "size = len(ip_list)\n",
    "# total no of unique ip addresses\n",
    "\n",
    "for i in range(size):\n",
    "    # iterate through all the ip addresses\n",
    "\n",
    "    reviews = ip_group.get_group( ip_list[i] )\n",
    "    # dataframe of each ip\n",
    "\n",
    "    dates_list = reviews[\"review_date\"].dropna().unique().tolist()\n",
    "    # list of dates of reviews by each ip addresses\n",
    "\n",
    "    reviews_by_date = reviews.groupby(\"review_date\");\n",
    "    # grouping the dataframe by date\n",
    "\n",
    "    for j in range(len(dates_list)):\n",
    "        # iterate through all the dates\n",
    "\n",
    "        reviews_by_date_for_pos = []\n",
    "        reviews_by_date_for_neg = []\n",
    "\n",
    "        reviews_for_each_day = reviews_by_date.get_group(dates_list[j])\n",
    "        #dataframe of reviews for a day by each ip addresses\n",
    "\n",
    "        indices = reviews_for_each_day.index.tolist()\n",
    "        # list of indices of the dataframe reviews_for_each_day\n",
    "\n",
    "        for k in range(len(reviews_for_each_day)):\n",
    "            #iterate through all the reviews on a day by each ip addresses\n",
    "\n",
    "            text = reviews_for_each_day[\"review_body\"][ indices[k] ]\n",
    "            # reviews on a day for an ip addresses\n",
    "\n",
    "            if(getSentiment(text) == 0):\n",
    "\n",
    "                #if sentiment is negative, append review_id to list of negative reviews\n",
    "                reviews_by_date_for_neg.append(reviews_for_each_day[\"review_id\"][ indices[k] ])\n",
    "            else:\n",
    "\n",
    "                #if sentiment is positive, append review_id to list of positive reviews\n",
    "                reviews_by_date_for_pos.append(reviews_for_each_day[\"review_id\"][ indices[k] ])\n",
    "\n",
    "        # CONDITION FOR CONSIDERING THE FAKE REVIEW\n",
    "\n",
    "        #removing postive reviews that are written by a reviewer that are > 3 on same day\n",
    "        if(len(reviews_by_date_for_pos)>3):\n",
    "            remove_reviews.extend(reviews_by_date_for_pos)\n",
    "\n",
    "        #removing postive reviews that are written by a reviewer that are > 3 on same day\n",
    "        if(len(reviews_by_date_for_neg)>3):\n",
    "            remove_reviews.extend(reviews_by_date_for_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xl6vj3PQUafI",
    "outputId": "73508563-6ede-45e9-fee5-5e4360efb5bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29532"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LW8jLwFlmEu"
   },
   "source": [
    "#6. Similar reviews posted in the same time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xEOnGCjUb7G"
   },
   "outputs": [],
   "source": [
    "#Similar reviews\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "df = df.reset_index(drop=True)  # Reset the index of the DataFrame and drop the previous index\n",
    "df.set_index(\"review_id\")\n",
    "df.sort_values(\"timestamp\",inplace=True)\n",
    "def OnlyStopwords(str):\n",
    "    words = nltk.word_tokenize(str)\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    if(len(words)==0):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "remove_reviews = []\n",
    "indices = []\n",
    "for i in range(len(df)):\n",
    "\n",
    "    reviews = [str(df[\"review_body\"][i])]\n",
    "\n",
    "    try:\n",
    "        tfidf_vectorizer.fit_transform(reviews)\n",
    "    except:\n",
    "        # reviews with one word and with no dictionary meaning will be invalid\n",
    "        # e.g- [\"c\",\"O.K.\"]\n",
    "        remove_reviews.append(df[\"review_id\"][i])\n",
    "        continue\n",
    "\n",
    "    Time = df[\"timestamp\"][i]\n",
    "    # timestamp of the review that will be compared\n",
    "\n",
    "    for j in range(i+1,len(df)):\n",
    "\n",
    "        indices.append(df.index[j])\n",
    "\n",
    "        if(df[\"timestamp\"][j]-Time <= 1800):\n",
    "            # reviews written in 30 min of intervals will be checked for same pattern\n",
    "            reviews.append(str(df[\"review_body\"][j]))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(reviews)\n",
    "\n",
    "    #creates TF-IDF Model\n",
    "    tfidf_list = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix).tolist()\n",
    "    # Creates matrix based on document similarity\n",
    "\n",
    "    # To check similarity b/w 2 reviews\n",
    "    i_appended = False\n",
    "    for k in range(1,len(tfidf_list[0])):\n",
    "        #print(tfidf_list[0][k],i+k)\n",
    "\n",
    "        if(tfidf_list[0][k]>0.6):\n",
    "            # 0.6 is defind for the simmilarity level\n",
    "\n",
    "            remove_reviews.append(df[\"review_id\"][i+k])\n",
    "            # i+k is to get the review id of the review\n",
    "\n",
    "            if(not i_appended):\n",
    "                remove_reviews.append(df[\"review_id\"][i])\n",
    "                i_appended = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O49rkWOIcYfQ",
    "outputId": "23556dd9-268b-4a10-ee0a-51deec33a4e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove_reviews)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
